{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Started with Nested Tensors\n",
    "===================================\n",
    "\n",
    "Nested tensors generalize the shape of regular dense tensors, allowing\n",
    "for representation of ragged-sized data.\n",
    "\n",
    "-   for a regular tensor, each dimension is regular and has a size\n",
    "-   for a nested tensor, not all dimensions have regular sizes; some of\n",
    "    them are ragged\n",
    "\n",
    "Nested tensors are a natural solution for representing sequential data\n",
    "within various domains:\n",
    "\n",
    "-   in NLP, sentences can have variable lengths, so a batch of sentences\n",
    "    forms a nested tensor\n",
    "-   in CV, images can have variable shapes, so a batch of images forms a\n",
    "    nested tensor\n",
    "\n",
    "In this tutorial, we will demonstrate basic usage of nested tensors and\n",
    "motivate their usefulness for operating on sequential data of varying\n",
    "lengths with a real-world example. In particular, they are invaluable\n",
    "for building transformers that can efficiently operate on ragged\n",
    "sequential inputs. Below, we present an implementation of multi-head\n",
    "attention using nested tensors that, combined usage of `torch.compile`,\n",
    "out-performs operating naively on tensors with padding.\n",
    "\n",
    "Nested tensors are currently a prototype feature and are subject to\n",
    "change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested tensor initialization\n",
    "============================\n",
    "\n",
    "From the Python frontend, a nested tensor can be created from a list of\n",
    "tensors. We denote nt\\[i\\] as the ith tensor component of a\n",
    "nestedtensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt=nested_tensor([\n",
      "  tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.,  9., 10., 11.]], device='cuda:0'),\n",
      "  tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
      "          [12., 13., 14., 15., 16., 17.]], device='cuda:0')\n",
      "], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "nt = torch.nested.nested_tensor([torch.arange(12).reshape(\n",
    "    2, 6), torch.arange(18).reshape(3, 6)], dtype=torch.float, device=device)\n",
    "print(f\"{nt=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By padding every underlying tensor to the same shape, a nestedtensor can\n",
    "be converted to a regular tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_out_tensor=tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.,  9., 10., 11.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15., 16., 17.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "padded_out_tensor = torch.nested.to_padded_tensor(nt, padding=0.0)\n",
    "print(f\"{padded_out_tensor=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tensors posses an attribute for determining if they are nested;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt is nested: True\n",
      "padded_out_tensor is nested: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"nt is nested: {nt.is_nested}\")\n",
    "print(f\"padded_out_tensor is nested: {padded_out_tensor.is_nested}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to construct nestedtensors from batches of irregularly\n",
    "shaped tensors. i.e. dimension 0 is assumed to be the batch dimension.\n",
    "Indexing dimension 0 gives back the first underlying tensor component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First underlying tensor component:\n",
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10., 11.]], device='cuda:0')\n",
      "last column of 2nd underlying tensor component:\n",
      "tensor([ 5., 11., 17.], device='cuda:0')\n",
      "First underlying tensor component is nested: False\n"
     ]
    }
   ],
   "source": [
    "print(\"First underlying tensor component:\", nt[0], sep='\\n')\n",
    "print(\"last column of 2nd underlying tensor component:\", nt[1, :, -1], sep='\\n')\n",
    "\n",
    "# When indexing a nestedtensor's 0th dimension, the result is a regular tensor.\n",
    "print(f\"First underlying tensor component is nested: {nt[0].is_nested}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important note is that slicing in dimension 0 has not been supported\n",
    "yet. Which means it not currently possible to construct a view that\n",
    "combines the underlying tensor components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested Tensor Operations\n",
    "========================\n",
    "\n",
    "As each operation must be explicitly implemented for nestedtensors,\n",
    "operation coverage for nestedtensors is currently narrower than that of\n",
    "regular tensors. For now, only basic operations such as index, dropout,\n",
    "softmax, transpose, reshape, linear, bmm are covered. However, coverage\n",
    "is being expanded. If you need certain operations, please file an\n",
    "[issue](https://github.com/pytorch/pytorch) to help us prioritize\n",
    "coverage.\n",
    "\n",
    "**reshape**\n",
    "\n",
    "The reshape op is for changing the shape of a tensor. Its full semantics\n",
    "for regular tensors can be found\n",
    "[here](https://pytorch.org/docs/stable/generated/torch.reshape.html).\n",
    "For regular tensors, when specifying the new shape, a single dimension\n",
    "may be -1, in which case it is inferred from the remaining dimensions\n",
    "and the number of elements.\n",
    "\n",
    "The semantics for nestedtensors are similar, except that -1 no longer\n",
    "infers. Instead, it inherits the old size (here 2 for `nt[0]` and 3 for\n",
    "`nt[1]`). -1 is the only legal size to specify for a jagged dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt_reshaped=nested_tensor([\n",
      "  tensor([[[ 0.,  1.,  2.],\n",
      "           [ 3.,  4.,  5.]],\n",
      "  \n",
      "          [[ 6.,  7.,  8.],\n",
      "           [ 9., 10., 11.]]], device='cuda:0'),\n",
      "  tensor([[[ 0.,  1.,  2.],\n",
      "           [ 3.,  4.,  5.]],\n",
      "  \n",
      "          [[ 6.,  7.,  8.],\n",
      "           [ 9., 10., 11.]],\n",
      "  \n",
      "          [[12., 13., 14.],\n",
      "           [15., 16., 17.]]], device='cuda:0')\n",
      "], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "nt_reshaped = nt.reshape(2, -1, 2, 3)\n",
    "print(f\"{nt_reshaped=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transpose**\n",
    "\n",
    "The transpose op is for swapping two dimensions of a tensor. Its full\n",
    "semantics can be found\n",
    "[here](https://pytorch.org/docs/stable/generated/torch.transpose.html).\n",
    "Note that for nestedtensors dimension 0 is special; it is assumed to be\n",
    "the batch dimension, so transposes involving nestedtensor dimension 0\n",
    "are not supported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt_transposed=nested_tensor([\n",
      "  tensor([[[ 0.,  1.,  2.],\n",
      "           [ 6.,  7.,  8.]],\n",
      "  \n",
      "          [[ 3.,  4.,  5.],\n",
      "           [ 9., 10., 11.]]], device='cuda:0'),\n",
      "  tensor([[[ 0.,  1.,  2.],\n",
      "           [ 6.,  7.,  8.],\n",
      "           [12., 13., 14.]],\n",
      "  \n",
      "          [[ 3.,  4.,  5.],\n",
      "           [ 9., 10., 11.],\n",
      "           [15., 16., 17.]]], device='cuda:0')\n",
      "], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "nt_transposed = nt_reshaped.transpose(1, 2)\n",
    "print(f\"{nt_transposed=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**others**\n",
    "\n",
    "Other operations have the same semantics as for regular tensors.\n",
    "Applying the operation on a nestedtensor is equivalent to applying the\n",
    "operation to the underlying tensor components, with the result being a\n",
    "nestedtensor as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Matmul:\n",
      " nested_tensor([\n",
      "  tensor([[[  0.7781,   1.7332,   2.5551,  -1.7998],\n",
      "           [ -6.3416,   0.6039,   3.3571, -21.6835]],\n",
      "  \n",
      "          [[ -3.0563,   1.1609,  -6.8225,  19.4126],\n",
      "           [ -7.3476,  -0.8315, -15.4485,  44.0489]]], device='cuda:0'),\n",
      "  tensor([[[ -0.7215,   3.0998,  -0.2846,   4.7335,   3.6254],\n",
      "           [-17.8239,   9.9335,  14.5221,  25.6358,  15.9261],\n",
      "           [-34.9263,  16.7672,  29.3289,  46.5381,  28.2268]],\n",
      "  \n",
      "          [[  5.9445,   3.1823,   7.7202, -15.5639,   9.8096],\n",
      "           [ 13.5947,   9.8521,  19.5695, -38.9003,  20.3403],\n",
      "           [ 21.2450,  16.5219,  31.4188, -62.2367,  30.8710]]], device='cuda:0')\n",
      "], device='cuda:0')\n",
      "Result of Dropout:\n",
      " nested_tensor([\n",
      "  tensor([[[  0.8646,   1.9258,   2.8390,  -1.9998],\n",
      "           [ -0.0000,   0.6710,   3.7301, -24.0928]],\n",
      "  \n",
      "          [[ -3.3959,   1.2899,  -0.0000,  21.5696],\n",
      "           [ -8.1640,  -0.9239, -17.1650,  48.9432]]], device='cuda:0'),\n",
      "  tensor([[[ -0.8017,   3.4442,  -0.3162,   5.2595,   0.0000],\n",
      "           [-19.8043,  11.0372,  16.1357,  28.4842,  17.6957],\n",
      "           [-38.8070,   0.0000,  32.5877,  51.7090,  31.3631]],\n",
      "  \n",
      "          [[  6.6050,   3.5359,   8.5781, -17.2933,  10.8996],\n",
      "           [ 15.1053,  10.9468,  21.7439, -43.2226,  22.6003],\n",
      "           [ 23.6055,  18.3577,  34.9098, -69.1519,  34.3011]]], device='cuda:0')\n",
      "], device='cuda:0')\n",
      "Result of Softmax:\n",
      " nested_tensor([\n",
      "  tensor([[[8.9692e-02, 2.5920e-01, 6.4599e-01, 5.1141e-03],\n",
      "           [2.2401e-02, 4.3820e-02, 9.3378e-01, 7.7075e-13]],\n",
      "  \n",
      "          [[1.4375e-11, 1.5583e-09, 4.2900e-10, 1.0000e+00],\n",
      "           [1.5800e-25, 2.2030e-22, 1.9480e-29, 1.0000e+00]]], device='cuda:0'),\n",
      "  tensor([[[1.9859e-03, 1.3866e-01, 3.2269e-03, 8.5170e-01, 4.4272e-03],\n",
      "           [1.0679e-21, 2.6476e-08, 4.3361e-06, 9.9998e-01, 2.0634e-05],\n",
      "           [4.8915e-40, 3.4921e-23, 4.9628e-09, 1.0000e+00, 1.4585e-09]],\n",
      "  \n",
      "          [[1.2264e-02, 5.6982e-04, 8.8210e-02, 5.1257e-13, 8.9896e-01],\n",
      "           [3.8999e-04, 6.0961e-06, 2.9797e-01, 1.8180e-29, 7.0163e-01],\n",
      "           [7.9792e-06, 4.1963e-08, 6.4764e-01, 0.0000e+00, 3.5236e-01]]],\n",
      "         device='cuda:0')\n",
      "], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "nt_mm = torch.nested.nested_tensor([torch.randn((2, 3, 4)), torch.randn((2, 3, 5))], device=device)\n",
    "nt3 = torch.matmul(nt_transposed, nt_mm)\n",
    "print(f\"Result of Matmul:\\n {nt3}\")\n",
    "\n",
    "nt4 = F.dropout(nt3, 0.1)\n",
    "print(f\"Result of Dropout:\\n {nt4}\")\n",
    "\n",
    "nt5 = F.softmax(nt4, -1)\n",
    "print(f\"Result of Softmax:\\n {nt5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Nested Tensor\n",
    "=================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data is sequential, it is often the case that each sample has a\n",
    "different length. For example, in a batch of sentences, each sentence\n",
    "has a different number of words. A common technique for handling varying\n",
    "sequences is to manually pad each data tensor to the same shape in order\n",
    "to form a batch. For example, we have 2 sentences with different lengths\n",
    "and a vocabulary In order to represent his as single tensor we pad with\n",
    "0 to the max length in the batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_sentences=tensor([[1., 2., 0.],\n",
      "        [3., 4., 5.]])\n",
      "nested_sentences=nested_tensor([\n",
      "  tensor([1., 2.]),\n",
      "  tensor([3., 4., 5.])\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "sentences = [[\"goodbye\", \"padding\"],\n",
    "             [\"embrace\", \"nested\", \"tensor\"]]\n",
    "vocabulary = {\"goodbye\": 1.0, \"padding\": 2.0,\n",
    "              \"embrace\": 3.0, \"nested\": 4.0, \"tensor\": 5.0}\n",
    "padded_sentences = torch.tensor([[1.0, 2.0, 0.0],\n",
    "                                 [3.0, 4.0, 5.0]])\n",
    "nested_sentences = torch.nested.nested_tensor([torch.tensor([1.0, 2.0]),\n",
    "                                               torch.tensor([3.0, 4.0, 5.0])])\n",
    "print(f\"{padded_sentences=}\")\n",
    "print(f\"{nested_sentences=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique of padding a batch of data to its max length is not\n",
    "optimal. The padded data is not needed for computation and wastes memory\n",
    "by allocating larger tensors than necessary. Further, not all operations\n",
    "have the same semnatics when applied to padded data. For matrix\n",
    "multiplications in order to ignore the padded entries, one needs to pad\n",
    "with 0 while for softmax one has to pad with -inf to ignore specific\n",
    "entries. The primary objective of nested tensor is to facilitate\n",
    "operations on ragged data using the standard PyTorch tensor UX, thereby\n",
    "eliminating the need for inefficient and complex padding and masking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2689, 0.7311, 0.0000],\n",
      "        [0.0900, 0.2447, 0.6652]])\n",
      "nested_tensor([\n",
      "  tensor([0.2689, 0.7311]),\n",
      "  tensor([0.0900, 0.2447, 0.6652])\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "padded_sentences_for_softmax = torch.tensor([[1.0, 2.0, float(\"-inf\")],\n",
    "                                             [3.0, 4.0, 5.0]])\n",
    "print(F.softmax(padded_sentences_for_softmax, -1))\n",
    "print(F.softmax(nested_sentences, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at a practical example: the multi-head attention\n",
    "component utilized in\n",
    "[Transformers](https://arxiv.org/pdf/1706.03762.pdf). We can implement\n",
    "this in such a way that it can operate on either padded or nested\n",
    "tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes multi-head attention. Supports nested or padded tensors.\n",
    "\n",
    "    Args:\n",
    "        E_q (int): Size of embedding dim for query\n",
    "        E_k (int): Size of embedding dim for key\n",
    "        E_v (int): Size of embedding dim for value\n",
    "        E_total (int): Total embedding dim of combined heads post input projection. Each head\n",
    "            has dim E_total // nheads\n",
    "        nheads (int): Number of heads\n",
    "        dropout_p (float, optional): Dropout probability. Default: 0.0\n",
    "    \"\"\"\n",
    "    def __init__(self, E_q: int, E_k: int, E_v: int, E_total: int,\n",
    "                 nheads: int, dropout_p: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.nheads = nheads\n",
    "        self.dropout_p = dropout_p\n",
    "        self.query_proj = nn.Linear(E_q, E_total)\n",
    "        self.key_proj = nn.Linear(E_k, E_total)\n",
    "        self.value_proj = nn.Linear(E_v, E_total)\n",
    "        self.qkv_proj = nn.Linear(E_q, 3 * E_total)\n",
    "        E_out = E_q\n",
    "        self.out_proj = nn.Linear(E_total, E_out)\n",
    "        assert E_total % nheads == 0, \"Embedding dim is not divisible by nheads\"\n",
    "        self.E_head = E_total // nheads\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass; runs the following process:\n",
    "            1. Apply input projection\n",
    "            2. Split heads and prepare for SDPA\n",
    "            3. Run SDPA\n",
    "            4. Apply output projection\n",
    "\n",
    "        Args:\n",
    "            query (torch.Tensor): query of shape (N, L_t, E_q)\n",
    "            key (torch.Tensor): key of shape (N, L_s, E_k)\n",
    "            value (torch.Tensor): value of shape (N, L_s, E_v)\n",
    "\n",
    "        Returns:\n",
    "            attn_output (torch.Tensor): output of shape (N, L_t, E_q)\n",
    "        \"\"\"\n",
    "        # # Step 1. Apply input projection\n",
    "        # # TODO: demonstrate packed projection\n",
    "        # query = self.query_proj(query)\n",
    "        # key = self.key_proj(key)\n",
    "        # value = self.value_proj(value)\n",
    "\n",
    "        query, key, value = self.qkv_proj(query).chunk(3, dim=-1)\n",
    "        print(\"hello\")\n",
    "\n",
    "        # Step 2. Split heads and prepare for SDPA\n",
    "        # reshape query, key, value to separate by head\n",
    "        # (N, L_t, E_total) -> (N, L_t, nheads, E_head) -> (N, nheads, L_t, E_head)\n",
    "        query = query.unflatten(-1, [self.nheads, self.E_head]).transpose(1, 2)\n",
    "        # (N, L_s, E_total) -> (N, L_s, nheads, E_head) -> (N, nheads, L_s, E_head)\n",
    "        key = key.unflatten(-1, [self.nheads, self.E_head]).transpose(1, 2)\n",
    "        # (N, L_s, E_total) -> (N, L_s, nheads, E_head) -> (N, nheads, L_s, E_head)\n",
    "        value = value.unflatten(-1, [self.nheads, self.E_head]).transpose(1, 2)\n",
    "\n",
    "        # Step 3. Run SDPA\n",
    "        # (N, nheads, L_t, E_head)\n",
    "        attn_output = F.scaled_dot_product_attention(\n",
    "            query, key, value, dropout_p=dropout_p, is_causal=True)\n",
    "        # (N, nheads, L_t, E_head) -> (N, L_t, nheads, E_head) -> (N, L_t, E_total)\n",
    "        attn_output = attn_output.transpose(1, 2).flatten(-2)\n",
    "\n",
    "        # Step 4. Apply output projection\n",
    "        # (N, L_t, E_total) -> (N, L_t, E_out)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set hyperparameters following [the Transformer\n",
    "paper](https://arxiv.org/pdf/1706.03762.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 512\n",
    "E_q, E_k, E_v, E_total = 512, 512, 512, 512\n",
    "E_out = E_q\n",
    "nheads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "except for dropout probability: set to 0 for correctness check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropout_p = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate some realistic fake data from Zipf\\'s law.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zipf_sentence_lengths(alpha: float, batch_size: int) -> torch.Tensor:\n",
    "    # generate fake corpus by unigram Zipf distribution\n",
    "    # from wikitext-2 corpus, we get rank \".\" = 3, \"!\" = 386, \"?\" = 858\n",
    "    sentence_lengths = np.empty(batch_size, dtype=int)\n",
    "    for ibatch in range(batch_size):\n",
    "        sentence_lengths[ibatch] = 1\n",
    "        word = np.random.zipf(alpha)\n",
    "        while word != 3 and word != 386 and word != 858:\n",
    "            sentence_lengths[ibatch] += 1\n",
    "            word = np.random.zipf(alpha)\n",
    "    return torch.tensor(sentence_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create nested tensor batch inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_batch(N, E_q, E_k, E_v, device):\n",
    "    # generate semi-realistic data using Zipf distribution for sentence lengths\n",
    "    sentence_lengths = zipf_sentence_lengths(alpha=1.2, batch_size=N)\n",
    "\n",
    "    # Note: the torch.jagged layout is a nested tensor layout that supports a single ragged\n",
    "    # dimension and works with torch.compile. The batch items each have shape (B, S*, D)\n",
    "    # where B = batch size, S* = ragged sequence length, and D = embedding dimension.\n",
    "    query = torch.nested.nested_tensor([\n",
    "        torch.randn(l.item(), E_q, device=device)\n",
    "        for l in sentence_lengths\n",
    "    ] , layout=torch.jagged, requires_grad=True)\n",
    "\n",
    "    key = torch.nested.nested_tensor([\n",
    "        torch.randn(s.item(), E_k, device=device)\n",
    "        for s in sentence_lengths\n",
    "    ], layout=torch.jagged)\n",
    "\n",
    "    value = torch.nested.nested_tensor([\n",
    "        torch.randn(s.item(), E_v, device=device)\n",
    "        for s in sentence_lengths\n",
    "    ], layout=torch.jagged)\n",
    "\n",
    "    return query, key, value, sentence_lengths\n",
    "\n",
    "query, key, value, sentence_lengths = gen_batch(N, E_q, E_k, E_v, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate padded forms of query, key, value for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jagged_to_padded(jt, padding_val):\n",
    "    # TODO: do jagged -> padded directly when this is supported\n",
    "    return torch.nested.to_padded_tensor(\n",
    "        torch.nested.nested_tensor(list(jt.unbind())),\n",
    "        padding_val)\n",
    "\n",
    "padded_query, padded_key, padded_value = (\n",
    "    jagged_to_padded(t, 0.0) for t in (query, key, value)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(E_q, E_k, E_v, E_total, nheads, dropout_p).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correctness and performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "=== without torch.compile ===\n",
      "nested and padded calculations differ by 1.1920928955078125e-06\n",
      "nested tensor multi-head attention takes 0.059736272000009194 seconds\n",
      "padded tensor multi-head attention takes 0.09523707599146292 seconds\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "=== with torch.compile ===\n",
      "nested and padded calculations differ by 1.1920928955078125e-06\n",
      "nested tensor multi-head attention takes 0.006561717003933154 seconds\n",
      "padded tensor multi-head attention takes 0.025924878995283507 seconds\n"
     ]
    }
   ],
   "source": [
    "def benchmark(func, *args, **kwargs):\n",
    "    torch.cuda.synchronize()\n",
    "    begin = timeit.default_timer()\n",
    "    output = func(*args, **kwargs)\n",
    "    torch.cuda.synchronize()\n",
    "    end = timeit.default_timer()\n",
    "    return output, (end - begin)\n",
    "\n",
    "output_nested, time_nested = benchmark(mha, query, key, value)\n",
    "output_padded, time_padded = benchmark(mha, padded_query, padded_key, padded_value)\n",
    "\n",
    "# padding-specific step: remove output projection bias from padded entries for fair comparison\n",
    "for i, entry_length in enumerate(sentence_lengths):\n",
    "    output_padded[i, entry_length:] = 0.0\n",
    "\n",
    "print(\"=== without torch.compile ===\")\n",
    "print(\"nested and padded calculations differ by\", (jagged_to_padded(output_nested, 0.0) - output_padded).abs().max().item())\n",
    "print(\"nested tensor multi-head attention takes\", time_nested, \"seconds\")\n",
    "print(\"padded tensor multi-head attention takes\", time_padded, \"seconds\")\n",
    "\n",
    "# warm up compile first...\n",
    "compiled_mha = torch.compile(mha)\n",
    "compiled_mha(query, key, value)\n",
    "# ...now benchmark\n",
    "compiled_output_nested, compiled_time_nested = benchmark(\n",
    "    compiled_mha, query, key, value)\n",
    "\n",
    "# warm up compile first...\n",
    "compiled_mha(padded_query, padded_key, padded_value)\n",
    "# ...now benchmark\n",
    "compiled_output_padded, compiled_time_padded = benchmark(\n",
    "    compiled_mha, padded_query, padded_key, padded_value)\n",
    "\n",
    "# padding-specific step: remove output projection bias from padded entries for fair comparison\n",
    "for i, entry_length in enumerate(sentence_lengths):\n",
    "    compiled_output_padded[i, entry_length:] = 0.0\n",
    "\n",
    "print(\"=== with torch.compile ===\")\n",
    "print(\"nested and padded calculations differ by\", (jagged_to_padded(compiled_output_nested, 0.0) - compiled_output_padded).abs().max().item())\n",
    "print(\"nested tensor multi-head attention takes\", compiled_time_nested, \"seconds\")\n",
    "print(\"padded tensor multi-head attention takes\", compiled_time_padded, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that without `torch.compile`, the overhead of the python subclass\n",
    "nested tensor can make it slower than the equivalent computation on\n",
    "padded tensors. However, once `torch.compile` is enabled, operating on\n",
    "nested tensors gives a multiple x speedup. Avoiding wasted computation\n",
    "on padding becomes only more valuable as the percentage of padding in\n",
    "the batch increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nested speedup: 3.951\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nested speedup: {compiled_time_padded / compiled_time_nested:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "==========\n",
    "\n",
    "In this tutorial, we have learned how to perform basic operations with\n",
    "nested tensors and how implement multi-head attention for transformers\n",
    "in a way that avoids computation on padding. For more information, check\n",
    "out the docs for the\n",
    "[torch.nested](https://pytorch.org/docs/stable/nested.html) namespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, j19, 3, 8, 64])\n",
      "Max length: 128\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([37, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([37, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([70, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([64, 3, 8, 64])\n",
      "Tensor shape: torch.Size([34, 3, 8, 64])\n",
      "Tensor shape: torch.Size([36, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([29, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([17, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([62, 3, 8, 64])\n",
      "Tensor shape: torch.Size([22, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([31, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([42, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([36, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([67, 3, 8, 64])\n",
      "Tensor shape: torch.Size([40, 3, 8, 64])\n",
      "Tensor shape: torch.Size([38, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([42, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([44, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([25, 3, 8, 64])\n",
      "Tensor shape: torch.Size([39, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([17, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([22, 3, 8, 64])\n",
      "Tensor shape: torch.Size([17, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([63, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([102, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([33, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([75, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([58, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([22, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([33, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([42, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([25, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([43, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([51, 3, 8, 64])\n",
      "Tensor shape: torch.Size([28, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([60, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([53, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([25, 3, 8, 64])\n",
      "Tensor shape: torch.Size([66, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([72, 3, 8, 64])\n",
      "Tensor shape: torch.Size([28, 3, 8, 64])\n",
      "Tensor shape: torch.Size([27, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([32, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([50, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([29, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([69, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([34, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([72, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([96, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([22, 3, 8, 64])\n",
      "Tensor shape: torch.Size([30, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([59, 3, 8, 64])\n",
      "Tensor shape: torch.Size([35, 3, 8, 64])\n",
      "Tensor shape: torch.Size([60, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([35, 3, 8, 64])\n",
      "Tensor shape: torch.Size([53, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([48, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([92, 3, 8, 64])\n",
      "Tensor shape: torch.Size([37, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([22, 3, 8, 64])\n",
      "Tensor shape: torch.Size([31, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([38, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([60, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([36, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([35, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([44, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([47, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([87, 3, 8, 64])\n",
      "Tensor shape: torch.Size([27, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([27, 3, 8, 64])\n",
      "Tensor shape: torch.Size([67, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([30, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([24, 3, 8, 64])\n",
      "Tensor shape: torch.Size([33, 3, 8, 64])\n",
      "Tensor shape: torch.Size([128, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([34, 3, 8, 64])\n",
      "Tensor shape: torch.Size([31, 3, 8, 64])\n",
      "Tensor shape: torch.Size([29, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([61, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([63, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([96, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([33, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([27, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([117, 3, 8, 64])\n",
      "Tensor shape: torch.Size([36, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([50, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([23, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([107, 3, 8, 64])\n",
      "Tensor shape: torch.Size([40, 3, 8, 64])\n",
      "Tensor shape: torch.Size([42, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([31, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([22, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([30, 3, 8, 64])\n",
      "Tensor shape: torch.Size([17, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([33, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([29, 3, 8, 64])\n",
      "Tensor shape: torch.Size([33, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([32, 3, 8, 64])\n",
      "Tensor shape: torch.Size([35, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([43, 3, 8, 64])\n",
      "Tensor shape: torch.Size([56, 3, 8, 64])\n",
      "Tensor shape: torch.Size([37, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([36, 3, 8, 64])\n",
      "Tensor shape: torch.Size([31, 3, 8, 64])\n",
      "Tensor shape: torch.Size([45, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([61, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([22, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([43, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([43, 3, 8, 64])\n",
      "Tensor shape: torch.Size([27, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([38, 3, 8, 64])\n",
      "Tensor shape: torch.Size([39, 3, 8, 64])\n",
      "Tensor shape: torch.Size([51, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([25, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([17, 3, 8, 64])\n",
      "Tensor shape: torch.Size([45, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([44, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([28, 3, 8, 64])\n",
      "Tensor shape: torch.Size([35, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([38, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([50, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([34, 3, 8, 64])\n",
      "Tensor shape: torch.Size([45, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([24, 3, 8, 64])\n",
      "Tensor shape: torch.Size([35, 3, 8, 64])\n",
      "Tensor shape: torch.Size([36, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([34, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([48, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([49, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([54, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([56, 3, 8, 64])\n",
      "Tensor shape: torch.Size([35, 3, 8, 64])\n",
      "Tensor shape: torch.Size([59, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([26, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([38, 3, 8, 64])\n",
      "Tensor shape: torch.Size([34, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([16, 3, 8, 64])\n",
      "Tensor shape: torch.Size([70, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([42, 3, 8, 64])\n",
      "Tensor shape: torch.Size([55, 3, 8, 64])\n",
      "Tensor shape: torch.Size([44, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([14, 3, 8, 64])\n",
      "Tensor shape: torch.Size([17, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([42, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([15, 3, 8, 64])\n",
      "Tensor shape: torch.Size([18, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([55, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([45, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([67, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([57, 3, 8, 64])\n",
      "Tensor shape: torch.Size([13, 3, 8, 64])\n",
      "Tensor shape: torch.Size([21, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([19, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([9, 3, 8, 64])\n",
      "Tensor shape: torch.Size([28, 3, 8, 64])\n",
      "Tensor shape: torch.Size([5, 3, 8, 64])\n",
      "Tensor shape: torch.Size([10, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([3, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([44, 3, 8, 64])\n",
      "Tensor shape: torch.Size([20, 3, 8, 64])\n",
      "Tensor shape: torch.Size([12, 3, 8, 64])\n",
      "Tensor shape: torch.Size([4, 3, 8, 64])\n",
      "Tensor shape: torch.Size([6, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([17, 3, 8, 64])\n",
      "Tensor shape: torch.Size([2, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([8, 3, 8, 64])\n",
      "Tensor shape: torch.Size([7, 3, 8, 64])\n",
      "Tensor shape: torch.Size([1, 3, 8, 64])\n",
      "Tensor shape: torch.Size([85, 3, 8, 64])\n",
      "Tensor shape: torch.Size([11, 3, 8, 64])\n",
      "Tensor shape: torch.Size([32, 3, 8, 64])\n",
      "Tensor shape: torch.Size([51, 3, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "dim = 64\n",
    "heads = 8\n",
    "temp_qkv = torch.cat([query, query, query],dim = -1)\n",
    "qkv = temp_qkv.unflatten(-1, [3, heads, dim])\n",
    "print(qkv.shape)\n",
    "query_list = list(qkv)\n",
    "\n",
    "max_length = 128\n",
    "print(\"Max length:\", max_length)\n",
    "\n",
    "# Print the shapes of the tensors in the query list\n",
    "for t in query_list:\n",
    "    print(\"Tensor shape:\", t.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, j19, 3, 8, 64])\n",
      "qkv0 requires_grad True\n",
      "Time taken for pointwise multiplication: 0.0513258810096886\n",
      "Time taken for pointwise multiplication with list comprehension: 0.06395369699748699\n",
      "Time taken for reassembly: 0.0026697169960243627\n",
      "Time taken for einsum: 0.08307680799043737\n",
      "Time taken for einsum with list comprehension: 0.06599850799830165\n",
      "Time taken for reassembly: 0.003352902000187896\n",
      "torch.Size([128, 3, 1, 64])\n",
      "torch.Size([512, j60, 3, 1, 64])\n",
      "qkv1 requires grad:  True\n",
      "qkv_temp requires grad:  False\n",
      "torch.Size([512, j19, 3, 8, 64])\n",
      "Time taken for cos and sin reshaping: 0.005554736009798944\n",
      "Time taken for pointwise multiplication with reshaped cos and sin: 0.0014531909982906654\n",
      "Time taken for reassembly: 0.00040532198909204453\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "aten.to_padded_tensor.default",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 107\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Check if gradients are preserved\u001b[39;00m\n\u001b[1;32m    106\u001b[0m loss \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_padded_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    109\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/axolotl/.venv/lib/python3.10/site-packages/torch/nested/_internal/nested_tensor.py:314\u001b[0m, in \u001b[0;36mNestedTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/axolotl/.venv/lib/python3.10/site-packages/torch/nested/_internal/nested_tensor.py:295\u001b[0m, in \u001b[0;36mNestedTensor.__torch_dispatch__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(func)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: aten.to_padded_tensor.default"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.enable_grad\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "qkv = torch.cat([query, query, query],dim = -1)\n",
    "qkv = qkv.unflatten(-1, [3, heads, dim])\n",
    "\n",
    "print(qkv.shape)\n",
    "\n",
    "print(\"qkv0 requires_grad\", qkv.requires_grad)\n",
    "\n",
    "# Example cos and sin tensors\n",
    "max_length = 128\n",
    "dim = 64\n",
    "cos = torch.ones(1, max_length, 3, 1, dim, device=device)\n",
    "sin = torch.zeros(1, max_length, 3, 1, dim, device=device)\n",
    "cos = cos.squeeze(0)\n",
    "sin = sin.squeeze(0)\n",
    "\n",
    "# Unbind the nested tensor into a list of regular tensors\n",
    "qkv_list = list(qkv.unbind())\n",
    "\n",
    "time1 = timeit.default_timer()\n",
    "# Apply the pointwise multiplication to each tensor in the list\n",
    "\n",
    "result_list = []\n",
    "for t in qkv_list:\n",
    "    length = t.shape[0]\n",
    "    cos_slice = cos[:length]\n",
    "    sin_slice = sin[:length]\n",
    "    result = (t * cos_slice) + (rotate_half(t) * sin_slice)\n",
    "    result_list.append(result)\n",
    "\n",
    "time2 = timeit.default_timer()\n",
    "\n",
    "[(t * cos[:t.shape[0]]) + (rotate_half(t) * sin[:t.shape[0]]) for t in qkv_list]\n",
    "\n",
    "time3 = timeit.default_timer()\n",
    "\n",
    "# Reassemble the list of tensors back into a nested tensor\n",
    "result_nested_tensor = torch.nested.as_nested_tensor(result_list)\n",
    "time4 = timeit.default_timer()\n",
    "\n",
    "print(\"Time taken for pointwise multiplication:\", time2 - time1)\n",
    "print(\"Time taken for pointwise multiplication with list comprehension:\", time3 - time2)\n",
    "print(\"Time taken for reassembly:\", time4 - time3)\n",
    "\n",
    "time1 = timeit.default_timer()\n",
    "# Apply the pointwise multiplication to each tensor in the list\n",
    "\n",
    "result_list = []\n",
    "for t in qkv_list:\n",
    "    length = t.shape[0]\n",
    "    cos_slice = cos[:length]\n",
    "    sin_slice = sin[:length]\n",
    "    result = torch.einsum('...ij,...ij->...ij', t, cos_slice) + torch.einsum('...ij,...ij->...ij', rotate_half(t), sin_slice)\n",
    "    result_list.append(result)\n",
    "\n",
    "time2 = timeit.default_timer()\n",
    "\n",
    "[(torch.einsum('...ij,...ij->...ij', t, cos[:t.shape[0]]) + torch.einsum('...ij,...ij->...ij', rotate_half(t), sin[:t.shape[0]])) for t in qkv_list]\n",
    "\n",
    "time3 = timeit.default_timer()\n",
    "\n",
    "# Reassemble the list of tensors back into a nested tensor\n",
    "result_nested_tensor = torch.nested.as_nested_tensor(result_list)\n",
    "time4 = timeit.default_timer()\n",
    "\n",
    "print(\"Time taken for einsum:\", time2 - time1)\n",
    "print(\"Time taken for einsum with list comprehension:\", time3 - time2)\n",
    "print(\"Time taken for reassembly:\", time4 - time3)\n",
    "\n",
    "time1 = timeit.default_timer()\n",
    "# Apply the pointwise multiplication to each tensor in the list\n",
    "\n",
    "print(cos.shape)\n",
    "cos = torch.nested.nested_tensor([cos[:length] for length in qkv.offsets().diff().tolist()], layout=torch.jagged, requires_grad=True)\n",
    "sin = torch.nested.nested_tensor([sin[:length] for length in qkv.offsets().diff().tolist()], layout=torch.jagged, requires_grad=True)\n",
    "print(cos.shape)\n",
    "\n",
    "time2 = timeit.default_timer()\n",
    "\n",
    "print(\"qkv1 requires grad: \", qkv.requires_grad)\n",
    "\n",
    "qkv_temp = (qkv._values * cos._values) + (rotate_half(qkv)._values * sin._values)\n",
    "\n",
    "time3 = timeit.default_timer()\n",
    "\n",
    "print(\"qkv_temp requires grad: \", qkv_temp.requires_grad)\n",
    "# Reassemble the list of tensors back into a nested tensor\n",
    "qkv = torch.nested.nested_tensor_from_jagged(qkv_temp, qkv.offsets())\n",
    "print(qkv.shape)\n",
    "\n",
    "time4 = timeit.default_timer()\n",
    "\n",
    "print(\"Time taken for cos and sin reshaping:\", time2 - time1)\n",
    "print(\"Time taken for pointwise multiplication with reshaped cos and sin:\", time3 - time2)\n",
    "print(\"Time taken for reassembly:\", time4 - time3)\n",
    "\n",
    "\n",
    "# Check if gradients are preserved\n",
    "loss = qkv.flatten(-3, -1).sum(dim=-1)\n",
    "loss = loss.to_padded_tensor(0.0)\n",
    "print(\"Loss:\", loss.shape)\n",
    "loss.backward()\n",
    "print(\"Gradients:\")\n",
    "for t in qkv.unbind():\n",
    "    print(t.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnested\u001b[38;5;241m.\u001b[39mnested_tensor_from_jagged(\n\u001b[1;32m     16\u001b[0m         src\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m     17\u001b[0m         tgt\u001b[38;5;241m.\u001b[39moffsets(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m         mb_get_size(src\u001b[38;5;241m.\u001b[39m_min_seqlen_tensor) \u001b[38;5;28;01mif\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39m_min_seqlen_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m mb_get_size(src\u001b[38;5;241m.\u001b[39m_min_seqlen_tensor),\n\u001b[1;32m     22\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mnested\u001b[38;5;241m.\u001b[39mnested_tensor([torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1536\u001b[39m), torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m1536\u001b[39m), torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m1536\u001b[39m), torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1536\u001b[39m)], device\u001b[38;5;241m=\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, layout\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mjagged)\n\u001b[1;32m     25\u001b[0m qkv \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, [\u001b[38;5;241m3\u001b[39m, heads, dim])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# qkv_padded = qkv.to_padded_tensor(0.0)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def packed_tensor_from_jagged(tensor):\n",
    "    offsets = tensor.offsets()\n",
    "    return torch.cat([t for t in tensor.unbind()], dim = 0), offsets\n",
    "\n",
    "def jagged_from_packed_tensor(tensor, offsets):\n",
    "    return torch.nested.nested_tensor_from_jagged(tensor, offsets)\n",
    "\n",
    "def coerce_offsets(src, tgt):\n",
    "    assert torch.eq(src.offsets(), tgt.offsets()).all().item()\n",
    "    assert src._ragged_idx == tgt._ragged_idx\n",
    "\n",
    "    def mb_get_size(t):\n",
    "        return t.shape[0] if t is not None else None\n",
    "\n",
    "    return torch.nested.nested_tensor_from_jagged(\n",
    "        src.values(),\n",
    "        tgt.offsets(),\n",
    "        None,\n",
    "        src._ragged_idx,\n",
    "        mb_get_size(src._max_seqlen_tensor) if tgt._max_seqlen_tensor is None else mb_get_size(src._max_seqlen_tensor),\n",
    "        mb_get_size(src._min_seqlen_tensor) if tgt._min_seqlen_tensor is None else mb_get_size(src._min_seqlen_tensor),\n",
    "    )\n",
    "\n",
    "qkv = torch.nested.nested_tensor([torch.randn(64, 1536), torch.randn(128, 1536), torch.randn(256, 1536), torch.randn(512, 1536)], device=device, requires_grad=True, layout=torch.jagged)\n",
    "qkv = qkv.unflatten(-1, [3, heads, dim])\n",
    "# qkv_padded = qkv.to_padded_tensor(0.0)\n",
    "\n",
    "print(qkv.shape)\n",
    "print(\"qkv0 requires_grad\", qkv.requires_grad)\n",
    "\n",
    "qkv, offsets = packed_tensor_from_jagged(qkv)\n",
    "print(qkv.shape)\n",
    "print(\"qkv requires_grad\", qkv.requires_grad)\n",
    "\n",
    "qkv = jagged_from_packed_tensor(qkv, offsets)\n",
    "print(qkv.shape)\n",
    "print(\"qkv requires_grad\", qkv.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,   1024,   2048,   3072,   4096,   5120,   6144,   7168,   8192,\n",
      "          9216,  10240,  11264,  12288,  13312,  14336,  15360,  16384,  17408,\n",
      "         18432,  19456,  20480,  21504,  22528,  23552,  24576,  25600,  26624,\n",
      "         27648,  28672,  29696,  30720,  31744,  32768,  33792,  34816,  35840,\n",
      "         36864,  37888,  38912,  39936,  40960,  41984,  43008,  44032,  45056,\n",
      "         46080,  47104,  48128,  49152,  50176,  51200,  52224,  53248,  54272,\n",
      "         55296,  56320,  57344,  58368,  59392,  60416,  61440,  62464,  63488,\n",
      "         64512,  65536,  66560,  67584,  68608,  69632,  70656,  71680,  72704,\n",
      "         73728,  74752,  75776,  76800,  77824,  78848,  79872,  80896,  81920,\n",
      "         82944,  83968,  84992,  86016,  87040,  88064,  89088,  90112,  91136,\n",
      "         92160,  93184,  94208,  95232,  96256,  97280,  98304,  99328, 100352,\n",
      "        101376, 102400, 103424, 104448, 105472, 106496, 107520, 108544, 109568,\n",
      "        110592, 111616, 112640, 113664, 114688, 115712, 116736, 117760, 118784,\n",
      "        119808, 120832, 121856, 122880, 123904, 124928, 125952, 126976, 128000,\n",
      "        129024, 130048, 131072, 132096, 133120, 134144, 135168, 136192, 137216,\n",
      "        138240, 139264, 140288, 141312, 142336, 143360, 144384, 145408, 146432,\n",
      "        147456, 148480, 149504, 150528, 151552, 152576, 153600, 154624, 155648,\n",
      "        156672, 157696, 158720, 159744, 160768, 161792, 162816, 163840, 164864,\n",
      "        165888, 166912, 167936, 168960, 169984, 171008, 172032, 173056, 174080,\n",
      "        175104, 176128, 177152, 178176, 179200, 180224, 181248, 182272, 183296,\n",
      "        184320, 185344, 186368, 187392, 188416, 189440, 190464, 191488, 192512,\n",
      "        193536, 194560, 195584, 196608, 197632, 198656, 199680, 200704, 201728,\n",
      "        202752, 203776, 204800, 205824, 206848, 207872, 208896, 209920, 210944,\n",
      "        211968, 212992, 214016, 215040, 216064, 217088, 218112, 219136, 220160,\n",
      "        221184, 222208, 223232, 224256, 225280, 226304, 227328, 228352, 229376,\n",
      "        230400, 231424, 232448, 233472, 234496, 235520, 236544, 237568, 238592,\n",
      "        239616, 240640, 241664, 242688, 243712, 244736, 245760, 246784, 247808,\n",
      "        248832, 249856, 250880, 251904, 252928, 253952, 254976, 256000, 257024,\n",
      "        258048, 259072, 260096, 261120, 262144, 263168, 264192, 265216, 266240,\n",
      "        267264, 268288, 269312, 270336, 271360, 272384, 273408, 274432, 275456,\n",
      "        276480, 277504, 278528, 279552, 280576, 281600, 282624, 283648, 284672,\n",
      "        285696, 286720, 287744, 288768, 289792, 290816, 291840, 292864, 293888,\n",
      "        294912, 295936, 296960, 297984, 299008, 300032, 301056, 302080, 303104,\n",
      "        304128, 305152, 306176, 307200, 308224, 309248, 310272, 311296, 312320,\n",
      "        313344, 314368, 315392, 316416, 317440, 318464, 319488, 320512, 321536,\n",
      "        322560, 323584, 324608, 325632, 326656, 327680, 328704, 329728, 330752,\n",
      "        331776, 332800, 333824, 334848, 335872, 336896, 337920, 338944, 339968,\n",
      "        340992, 342016, 343040, 344064, 345088, 346112, 347136, 348160, 349184,\n",
      "        350208, 351232, 352256, 353280, 354304, 355328, 356352, 357376, 358400,\n",
      "        359424, 360448, 361472, 362496, 363520, 364544, 365568, 366592, 367616,\n",
      "        368640, 369664, 370688, 371712, 372736, 373760, 374784, 375808, 376832,\n",
      "        377856, 378880, 379904, 380928, 381952, 382976, 384000, 385024, 386048,\n",
      "        387072, 388096, 389120, 390144, 391168, 392192, 393216, 394240, 395264,\n",
      "        396288, 397312, 398336, 399360, 400384, 401408, 402432, 403456, 404480,\n",
      "        405504, 406528, 407552, 408576, 409600, 410624, 411648, 412672, 413696,\n",
      "        414720, 415744, 416768, 417792, 418816, 419840, 420864, 421888, 422912,\n",
      "        423936, 424960, 425984, 427008, 428032, 429056, 430080, 431104, 432128,\n",
      "        433152, 434176, 435200, 436224, 437248, 438272, 439296, 440320, 441344,\n",
      "        442368, 443392, 444416, 445440, 446464, 447488, 448512, 449536, 450560,\n",
      "        451584, 452608, 453632, 454656, 455680, 456704, 457728, 458752, 459776,\n",
      "        460800, 461824, 462848, 463872, 464896, 465920, 466944, 467968, 468992,\n",
      "        470016, 471040, 472064, 473088, 474112, 475136, 476160, 477184, 478208,\n",
      "        479232, 480256, 481280, 482304, 483328, 484352, 485376, 486400, 487424,\n",
      "        488448, 489472, 490496, 491520, 492544, 493568, 494592, 495616, 496640,\n",
      "        497664, 498688, 499712, 500736, 501760, 502784, 503808, 504832, 505856,\n",
      "        506880, 507904, 508928, 509952, 510976, 512000, 513024, 514048, 515072,\n",
      "        516096, 517120, 518144, 519168, 520192, 521216, 522240, 523264, 524288],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "seq_len = 1024\n",
    "batch_size = 512\n",
    "\n",
    "cu_seqlens = torch.arange(\n",
    "                0, (batch_size + 1) * seq_len, step=seq_len,\n",
    "                dtype=torch.int32\n",
    ")\n",
    "\n",
    "print(cu_seqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 1, 768])\n",
      "Forward hook for LayerNorm: input shape torch.Size([8, 1, 768]), output shape torch.Size([8, 1, 768])\n",
      "Forward hook for LayerNorm: input shape torch.Size([8, 1, 768]), output shape torch.Size([8, 1, 768])\n",
      "After norm1 shape: torch.Size([8, 1, 768])\n",
      "Forward hook for Linear: input shape torch.Size([8, 1, 768]), output shape torch.Size([8, 1, 2304])\n",
      "After attn_qkv shape: torch.Size([8, 1, 2304])\n",
      "Forward hook for DDiTBlock: input shape torch.Size([8, 1, 768]), output shape torch.Size([8, 1, 768])\n",
      "Backward hook for LayerNorm: grad_input shape torch.Size([8, 1, 768]), grad_output shape torch.Size([8, 1, 768])\n",
      "Backward hook for LayerNorm: grad_input shape torch.Size([8, 1, 768]), grad_output shape torch.Size([8, 1, 768])\n",
      "Backward hook for DDiTBlock: grad_input shape torch.Size([8, 1, 768]), grad_output shape torch.Size([8, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "from model import SEDD_nested\n",
    "\n",
    "# Example usage\n",
    "model = SEDD_nested(\n",
    "input_tensor = torch.randn(8, 1, 768, requires_grad=True)\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    print(f\"Forward hook for {module.__class__.__name__}: input shape {input[0].shape}, output shape {output.shape}\")\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    print(f\"Backward hook for {module.__class__.__name__}: grad_input shape {grad_input[0].shape}, grad_output shape {grad_output[0].shape}\")\n",
    "\n",
    "\n",
    "# Register hooks\n",
    "for name, module in model.named_modules():\n",
    "    module.register_forward_hook(forward_hook)\n",
    "    module.register_backward_hook(backward_hook)\n",
    "\n",
    "# Perform forward and backward pass\n",
    "output = model(input_tensor, None, None)\n",
    "loss = output.sum()\n",
    "\n",
    "make_dot(output.sum(), params=dict(model.named_parameters()))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Function AddBackward0 returned an invalid gradient at index 0 - got [1, 4, 64] but expected shape compatible with [4, 1, 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m output, offsets \u001b[38;5;241m=\u001b[39m packed_tensor_from_jagged(output)\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 47\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# This line throws an error (Function AddBackward0 returned an invalid gradient at index 0 - got [1, 4, 64] but expected shape compatible with [4, 1, 64])\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m###\u001b[39;00m\n",
      "File \u001b[0;32m~/axolotl/.venv/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/axolotl/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/axolotl/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function AddBackward0 returned an invalid gradient at index 0 - got [1, 4, 64] but expected shape compatible with [4, 1, 64]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def packed_tensor_from_jagged(tensor):\n",
    "    offsets = tensor.offsets()\n",
    "    return torch.cat([t for t in tensor.unbind()], dim = 0), offsets\n",
    "\n",
    "def modulate(x, shift, scale):\n",
    "\n",
    "    if scale is not None:\n",
    "        x = x * (1 + scale)\n",
    "    if shift is not None:\n",
    "        x = x + shift\n",
    "    return x\n",
    "\n",
    "class test_model(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.modulation = nn.Linear(dim, 2 * dim)\n",
    "\n",
    "    def forward(self, x, c): # x is a ragged tensor (batch_size=4, j, dim=64), c is a regular tensor (batch_size=4, dim=64)\n",
    "        shift, scale = self.modulation(c).chunk(2, dim=-1)\n",
    "        shift, scale = shift.unsqueeze(1), scale.unsqueeze(1) # I think it has something to do with this unsqueeze\n",
    "\n",
    "        return modulate(x, shift, scale)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = test_model(64).to(device)\n",
    "\n",
    "### This seems to work fine\n",
    "batch =torch.randn(4, 512, 64, device=device, requires_grad=True) # batch_size=4, j=512, dim=64\n",
    "c = torch.randn(4, 64, device=device, requires_grad=True) # batch_size=4, dim=64\n",
    "\n",
    "output = model(batch, c)\n",
    "loss = output.sum(dim=-1).mean()\n",
    "loss.backward()\n",
    "###\n",
    "\n",
    "### Bug here, when using nested tensors\n",
    "batch = torch.nested.nested_tensor([torch.randn(64, 64), torch.randn(128, 64), torch.randn(256, 64), torch.randn(512, 64)], device=device, requires_grad=True, layout=torch.jagged) # batch_size=4, j=jagged, dim=64\n",
    "c = torch.randn(4, 64, device=device, requires_grad=True) # batch_size=4, dim=64\n",
    "\n",
    "output = model(batch, c)\n",
    "output, offsets = packed_tensor_from_jagged(output)\n",
    "loss = output.sum(dim=-1).mean()\n",
    "loss.backward() # This line throws an error (Function AddBackward0 returned an invalid gradient at index 0 - got [1, 4, 64] but expected shape compatible with [4, 1, 64])\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
