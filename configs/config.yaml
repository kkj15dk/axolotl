defaults:
  - _self_
  - model: medium
  - override hydra/launcher: basic # submitit_slurm

ngpus: 8 #8 # number of GPUs to use. 8 x A100 40GB
tokens: 23 # 23 for uniform
num_labels: 3 # prokaryotic (0), eukaryotic (1), archeal (2)
prediction_type: 'x0' # 'log_score', 'x0', or 'x0_flow'

train_lora: False # if True, use LoRA for fine-tuning

# length: 4096
# A100 40GB
# small => batch_size=64
# medium => batch_size=32

# # A100 80GB
# # small => batch_size=32
# # medium => batch_size=8

# max_length: 1024
# A100 40GB
# small => batch_size=32, maybe 64 (but OOM usually)
# medium => batch_size=16 (just barely)

training:
  batch_size: 256
  drop_last: True
  num_workers: 4
  accum: 2 # 1 for small, 2 for medium
  n_iters: 1000000
  snapshot_freq: 2500
  log_freq: 50
  eval_freq: 100
  snapshot_freq_for_preemption: 1000
  weight: standard
  snapshot_sampling: True
  snapshot_checkpoint: True
  ema: 0.9999
  t_sampling: 'uniform' # 'antithetic' or 'uniform'

data:
  # name: IPR036736_90_grouped
  # train_path: /home/kkj/axolotl/datasets/IPR036736_90_grouped/train
  # valid_path: /home/kkj/axolotl/datasets/IPR036736_90_grouped/valid
  # tokenizer_path: '/home/kkj/axolotl/tokenizer/tokenizer_absorb'
  # name: IPR036736_90_grouped
  # train_path: /work3/s204514/datasets/IPR036736_90_grouped/train
  # valid_path: /work3/s204514/datasets/IPR036736_90_grouped/valid
  # tokenizer_path: '/zhome/fb/0/155603/axolotl/tokenizer/tokenizer_absorb'
  # name: UniRef50_grouped
  # train_path: /work3/s204514/datasets/UniRef50_grouped/train
  # valid_path: /work3/s204514/datasets/UniRef50_grouped/valid
  # tokenizer_path: '/zhome/fb/0/155603/axolotl/tokenizer/tokenizer_absorb'
  # tokenizer_path: '/zhome/fb/0/155603/axolotl/tokenizer/tokenizer_uniform'
  # name: UniRef50_grouped
  # train_path: /scratch/project/eu-25-27/datasets/UniRef50_grouped/train
  # valid_path: /scratch/project/eu-25-27/datasets/UniRef50_grouped/valid
  # tokenizer_path: '/home/it4i-kkj15/axolotl/tokenizer/tokenizer_absorb'
  # name: UniRef50_unclustered
  # train_path: /home/kkj/protein_databases/UniRef50_unclustered/test
  # valid_path: /home/kkj/protein_databases/UniRef50_unclustered/valid
  # tokenizer_path: '/home/kkj/axolotl/tokenizer/tokenizer_absorb'
  # use_unclustered_dataset: True # if True, use the dataloader meant for unclustered datasets
  # name: Thermo50
  # train_path: /home/kkj/protein_databases/ThermophileProteins_clustered_50_sorted_grouped/train
  # valid_path: /home/kkj/protein_databases/ThermophileProteins_clustered_50_sorted_grouped/valid
  # tokenizer_path: '/home/kkj/axolotl/tokenizer/tokenizer_absorb'
  # use_unclustered_dataset: False # if True, use the dataloader meant for unclustered datasets
  name: UniRef50_unclustered
  train_path: /scratch/project/eu-25-27/datasets/UniRef50_unclustered/train
  valid_path: /scratch/project/eu-25-27/datasets/UniRef50_unclustered/valid
  tokenizer_path: '/home/it4i-kkj15/axolotl/tokenizer/tokenizer_absorb'
  use_unclustered_dataset: True # if True, use the dataloader meant for unclustered datasets
  # name: Thermo50
  # train_path: /scratch/project/eu-25-27/datasets/ThermophileProteins_clustered_50_sorted_grouped/train
  # valid_path: /scratch/project/eu-25-27/datasets/ThermophileProteins_clustered_50_sorted_grouped/valid
  # tokenizer_path: '/home/it4i-kkj15/axolotl/tokenizer/tokenizer_absorb'
  # use_unclustered_dataset: False # if True, use the dataloader meant for unclustered datasets


graph:
  type: absorb # 'absorb', 'uniform' or 'flow'
  file: data
  report_all: False

noise:
  type: cosine # 'linear', 'cosine', or 'geometric'
  eps: 1e-4
  sigma_min: 1e-4
  sigma_max: 20

sampling:
  predictor: ancestral_x0 # 'euler_score', 'analytic_score, or 'ancestral_x0' 
  steps: 64
  length: 256
  noise_removal: True
  cfg: 0 # cfg_w = 0 => unconditional. cfg_w = 1 => conditional. 0 < cfg_w < 1 => interpolation. cfg_w > 1 => extrapolation. cfg_w = 'testing' => testing different cfg_w at once
  label: 'random' # one of 'random', 'archeal', 'eukaryotic', or 'prokaryotic'. 'random' gives a mix of labels

eval:
  batch_size: 512
  perplexity: True
  perplexity_batch_size: 64 # OBS: Shouldn't be more than eval.batch_size // n_gpus

optim:
  weight_decay: 0
  optimizer: AdamW
  lr: 3e-4
  beta1: 0.9
  beta2: 0.999
  eps: 1e-8
  warmup: 2500
  grad_clip: 1.

wandb:
  use_wandb: True
  entity: kkj15dk-axolotl
  project: axolotl
  name: null
  id: null

hydra:
  run:
    # dir: exp_local/${data.name}/${now:%Y.%m.%d}/${now:%H%M%S}
    # dir: /work3/s204514/exp_local/${data.name}/${now:%Y.%m.%d}/${now:%H%M%S}
    dir: /scratch/project/eu-25-27/exp_local/${data.name}/${now:%Y.%m.%d}/${now:%H%M%S}
  sweep:
    dir: exp/${data.name}/${now:%Y.%m.%d}/${now:%H%M%S}
    subdir: ${hydra.job.num}
  launcher:
    # max_num_timeout: 100000
    # # timeout_min: 10079
    # partition: g40x
    # account: stanford
    # mem_gb: 96
    # cpus_per_task: 40
    # gpus_per_node: ${ngpus}
    # constraint: null

load_dir: /scratch/project/eu-25-27/exp_local/UniRef50_unclustered/2025.08.22/113333 #/scratch/project/eu-25-27/exp_local/Thermo50/medium_for_finetuning